{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d4accc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77e6c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b47c2a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = pd.read_csv('test_data.csv') \n",
    "train_csv = pd.read_csv('train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfe9f611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I did not enjoy the film Eraser whatsoever. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Be very afraid of anyone who likes this film. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The 3rd and last big screen spin off from the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barely three and a half years after just scrap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm a big fan of the demonic puppets. Looking ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  I did not enjoy the film Eraser whatsoever. It...  0\n",
       "1  Be very afraid of anyone who likes this film. ...  0\n",
       "2  The 3rd and last big screen spin off from the ...  0\n",
       "3  Barely three and a half years after just scrap...  1\n",
       "4  I'm a big fan of the demonic puppets. Looking ...  0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "580865b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3ebcf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ayush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0c6a14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_non = train_csv['0']   # '0' refers to the review text\n",
    "train_y = train_csv['1']       # '1' corresponds to Label (1 - positive and 0 - negative)\n",
    "test_X_non = test_csv['0']\n",
    "test_y = test_csv['1']\n",
    "\n",
    "train_X=[]\n",
    "test_X=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d48da29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ayush\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff08434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text pre processing for training set\n",
    "\n",
    "for i in range(0, len(train_X_non)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', train_X_non[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [lemmatizer.lemmatize(word) for word in review if not word in set(stopwords)]\n",
    "    review = ' '.join(review)\n",
    "    train_X.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e02cdcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text pre processing for test set\n",
    "\n",
    "for i in range(0, len(test_X_non)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', test_X_non[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [lemmatizer.lemmatize(word) for word in review if not word in set(stopwords)]\n",
    "    review = ' '.join(review)\n",
    "    test_X.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "325ecd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eddie murphy delirious far funniest thing ever see life compare movie garuntee decide delirious funniest movie ever movie hr min throughout time barely moment laughing laugh hour replaying punch line head eddie murphy given many funny performance career hr trading place beverly hill cop raw coming america nutty professor shrek etc far hilarious moment seen movie many time funnier every time never loses edge day forward every great stand performance emulated delirious two thumb'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46b4b477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 25000, n_features: 65498\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF vectorization timeeee\n",
    "tf_idf = TfidfVectorizer()\n",
    "X_train_tf = tf_idf.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c2b774f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 25000, n_features: 65498\n"
     ]
    }
   ],
   "source": [
    "X_train_tf = tf_idf.transform(train_X)\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba96d8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 25000, n_features: 65498\n"
     ]
    }
   ],
   "source": [
    "X_test_tf = tf_idf.transform(test_X)\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test_tf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80124280",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a0d602d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#naive bayes classifier\n",
    "\n",
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(X_train_tf, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20b7b295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted y\n",
    "\n",
    "y_pred = naive_bayes_classifier.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdd61f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.80      0.88      0.84     12500\n",
      "    Negative       0.87      0.78      0.82     12500\n",
      "\n",
      "    accuracy                           0.83     25000\n",
      "   macro avg       0.83      0.83      0.83     25000\n",
      "weighted avg       0.83      0.83      0.83     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_y, y_pred,\n",
    "                                            target_names=['Positive', 'Negative']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb3556a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[10990  1510]\n",
      " [ 2693  9807]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\")\n",
    "print(metrics.confusion_matrix(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928b9373",
   "metadata": {},
   "source": [
    "# Doing a Test Predicton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b6cb87ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[\"This is quite possible one of the lengthiest short films I have ever seen, and I don't mean that in a good way. Hefty's initial flaw is its abysmal script, it's clear that the writer is an amateur at best. The movie goes on and on with no seeming end in mind. The ending is boring and a let down. The thing that grinds my gears the most about this movie is that it had no MaGuffin. I was waiting for it the whole time, and it never came. I'm really glad that this movie could not be released because of the copyrighted eagles music,Thank god for Glen Fry because without him the world would be in a pain on parallel to the Holocaust.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "244dee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = re.sub('[^a-zA-Z]', ' ', test[0])\n",
    "review = review.lower()\n",
    "review = review.split()\n",
    "review = [lemmatizer.lemmatize(word) for word in review if not word in set(stopwords)]\n",
    "test_processed =[ ' '.join(review)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "faa40b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quite possible one lengthiest short film ever seen mean good way hefty initial flaw abysmal script clear writer amateur best movie go seeming end mind ending boring let thing grind gear movie maguffin waiting whole time never came really glad movie could released copyrighted eagle music thank god glen fry without world would pain parallel holocaust']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a54914eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 65498)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = tf_idf.transform(test_processed)\n",
    "test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9c096ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad Review\n"
     ]
    }
   ],
   "source": [
    "#0= bad review\n",
    "#1= good review\n",
    "\n",
    "res=naive_bayes_classifier.predict(test_input)[0]\n",
    "\n",
    "if res==1:\n",
    "    print(\"Good Review\")\n",
    "    \n",
    "elif res==0:\n",
    "    print(\"Bad Review\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8630bfea",
   "metadata": {},
   "source": [
    "# Using Logistic regression instead of Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "579417e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4f33d8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_classifier = LogisticRegression()\n",
    "LR_classifier.fit(X_train_tf, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "807dbb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = LR_classifier.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cf43d161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.88      0.88      0.88     12500\n",
      "    Negative       0.88      0.88      0.88     12500\n",
      "\n",
      "    accuracy                           0.88     25000\n",
      "   macro avg       0.88      0.88      0.88     25000\n",
      "weighted avg       0.88      0.88      0.88     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_y, y_pred,\n",
    "                                            target_names=['Positive', 'Negative']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "01c2bb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[10998  1502]\n",
      " [ 1514 10986]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\")\n",
    "print(metrics.confusion_matrix(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "11ac1703",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[\"John Prusak is a great filmmaker, but more importantly, he's a great film _teacher_. His students have gone on to do big stuff in Hollywood (like Doug Chiang, at ILM). This was a side project, and it gave John the chance to showcase a classic piece of Detroit's history. It's an entertaining short film, and talks about what success is really all about.\"]\n",
    "review = re.sub('[^a-zA-Z]', ' ', test[0])\n",
    "review = review.lower()\n",
    "review = review.split()\n",
    "review = [lemmatizer.lemmatize(word) for word in review if not word in set(stopwords)]\n",
    "test_processed =[ ' '.join(review)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6a28b39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 65498)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = tf_idf.transform(test_processed)\n",
    "test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "84ceaeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Review\n"
     ]
    }
   ],
   "source": [
    "#0= bad review\n",
    "#1= good review\n",
    "\n",
    "res=LR_classifier.predict(test_input)[0]\n",
    "\n",
    "if res==1:\n",
    "    print(\"Good Review\")\n",
    "    \n",
    "elif res==0:\n",
    "    print(\"Bad Review\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
